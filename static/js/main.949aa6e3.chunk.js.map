{"version":3,"sources":["pages/Collect.js","App.js","reportWebVitals.js","index.js"],"names":["targetLabel","inputs","brain","collecting","classify","finalGesture","Collect","useState","recordCount","setRecordCount","recordStatus","setRecordStatus","loadingStatus","setLoadingStatus","inputEl","useRef","webcamRef","init","modelLoaded","a","console","log","video","current","videoWidth","videoHeight","width","height","options","outputs","task","debug","ml5","on","detect","useEffect","poses","length","i","landmarks","push","target","addData","gotResult","startClass","setInterval","error","results","confidence","label","save","ref","audio","mirrored","style","type","onClick","value","setTimeout","recordTime","normalizeData","train","epochs","handleSave","App","className","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"gKAKIA,EACAC,EACAC,E,mGAHAC,GAAa,EAIbC,GAAW,EACXC,EAAe,GAwKJC,MApKf,WAAoB,IAAD,EAEuBC,mBAAS,GAFhC,mBAERC,EAFQ,KAEKC,EAFL,OAGyBF,mBAAS,IAHlC,mBAGRG,EAHQ,KAGMC,EAHN,OAI2BJ,mBAAS,2BAJpC,mBAIRK,EAJQ,KAIOC,EAJP,KAMTC,EAAUC,iBAAO,MACjBC,EAAYD,iBAAO,MAEnBE,EAAI,uCAAG,yBAmBAC,EAnBA,SAAAC,EAAA,sDAmBAD,EAnBA,WAoBLE,QAAQC,IAAI,0BACZR,EAAiB,sDApBfS,EAAQN,EAAUO,QAAQD,MAC1BE,EAAaF,EAAME,WACnBC,EAAcH,EAAMG,YAE1BH,EAAMI,MAAQF,EACdF,EAAMK,OAASF,EACfL,QAAQC,IAAIC,EAAMI,OAEdE,EAAU,CACV3B,OAAQ,GACR4B,QAASrB,EACTsB,KAAM,iBACNC,OAAO,GAGX7B,EAAQ8B,gBAAkBJ,GAETI,WAAaV,EAAOJ,GAK5Be,GAAG,UAAWC,GAvBd,4CAAH,qDA0BVC,qBAAU,WACNlB,MACD,IAGH,IAAMiB,EAAS,SAACE,GACZ,GAAIjC,GAAcC,EAAU,CACxB,GAAIgC,EAAMC,OAAS,EAAG,CAClBpC,EAAS,GACT,IAAK,IAAIqC,EAAI,EAAGA,EAAIF,EAAM,GAAGG,UAAUF,OAAQC,IAC3CrC,EAAOuC,KAAKJ,EAAM,GAAGG,UAAUD,GAAG,IAClCrC,EAAOuC,KAAKJ,EAAM,GAAGG,UAAUD,GAAG,IAG1C,GAAInC,EAAY,CACZiB,QAAQC,IAAIpB,GACZ,IAAIwC,EAAS,CAACzC,GACdE,EAAMwC,QAAQzC,EAAQwC,QACfrC,GACPF,EAAME,SAASH,EAAQ0C,KA6CnC,SAASC,IACLxC,GAAW,EAKXyC,aAAY,WACRlC,EAAgBN,KACjB,KAQP,SAASsC,EAAUG,EAAOC,GAClBA,EAAQ,GAAGC,WAAa,MACxB5B,QAAQC,IAAI0B,EAAQ,GAAGE,OACvB5C,EAAe0C,EAAQ,GAAGE,OAtHnB,4CA4Hf,sBAAA9B,EAAA,sDACIjB,EAAMgD,OADV,4CA5He,sBAgIf,OACI,gCACI,8BACI,4CAEJ,8BACI,6BAAKtC,MAGT,cAAC,EAAD,CAAQuC,IAAKnC,EACToC,OAAO,EACPC,UAAU,EACVC,MAAO,CACH5B,MAAO,IACPC,OAAQ,OAEhB,gCACI,8BACI,6BAAKjB,MAET,gCACI,uBAAOyC,IAAKrC,EAASyC,KAAK,SAC1B,wBAAQC,QA1ExB,WACI/C,EAAeD,EAAc,GAC7BR,EAAcc,EAAQS,QAAQkC,MAC9B9C,EAAgB,aAfhBS,QAAQC,IAAIrB,GACZG,GAAa,EACbiB,QAAQC,IAAI,mBACZqC,YAAW,WACPvD,GAAa,EACVK,GAAe,GACdK,EAAiB,2DAErBF,EAAgB,MACjBgD,MA6ES,uBAEJ,8BACI,8BAAK,6BAAKnD,EAAc,iCAE5B,wBAAQgD,QAAS,kBAtEzBtD,EAAM0D,qBACN1D,EAAM2D,MAAM,CAAEC,OAAQ,KAAM,WACxB1C,QAAQC,IAAI,iBACZR,EAAiB,qGAmEb,mBACA,wBAAQ2C,QAAS,kBAAMZ,KAAvB,sBACA,wBAAQY,QAAS,kBA9CzBpD,GAAW,OACXC,EAAe,KA6CP,kBACA,wBAAQmD,QAAS,kBA9Jd,0CA8JoBO,IAAvB,4CC9JDC,MARf,WACE,OACE,qBAAKC,UAAU,MAAf,SACE,cAAC,EAAD,OCISC,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,M","file":"static/js/main.949aa6e3.chunk.js","sourcesContent":["import React, { useRef, useEffect, useState } from 'react'\nimport * as ml5 from 'ml5';\nimport * as Webcam from 'react-webcam';\n\nlet collecting = false;\nlet targetLabel;\nlet inputs;\nlet brain;\nlet classify = false\nlet finalGesture = \"\";\n// const classifySpeed = 300;\nconst recordTime = 5\n\nfunction Collect() {\n\n    const [recordCount, setRecordCount] = useState(0)\n    const [recordStatus, setRecordStatus] = useState(\"\")\n    const [loadingStatus, setLoadingStatus] = useState(\"Please Wait! Loading...\")\n\n    const inputEl = useRef(null);\n    const webcamRef = useRef(null);\n\n    const init = async () => {\n        const video = webcamRef.current.video;\n        const videoWidth = video.videoWidth;\n        const videoHeight = video.videoHeight;\n\n        video.width = videoWidth;\n        video.height = videoHeight;\n        console.log(video.width);\n\n        let options = {\n            inputs: 42,\n            outputs: recordCount,\n            task: 'classification',\n            debug: true\n        }\n\n        brain = ml5.neuralNetwork(options);\n\n        const handpose = ml5.handpose(video, modelLoaded);\n        function modelLoaded() {\n            console.log('HandPose Model Loaded!');\n            setLoadingStatus(\"Step 1: Name and record at least 2 hand gestures!\")\n        }\n        handpose.on('predict', detect);\n    }\n\n    useEffect(() => {\n        init()\n    }, [])\n\n\n    const detect = (poses) => {\n        if (collecting || classify) {\n            if (poses.length > 0) {\n                inputs = [];\n                for (let i = 0; i < poses[0].landmarks.length; i++) {\n                    inputs.push(poses[0].landmarks[i][0]);\n                    inputs.push(poses[0].landmarks[i][1]);\n                }\n            }\n            if (collecting) {\n                console.log(inputs);\n                let target = [targetLabel];\n                brain.addData(inputs, target);\n            } else if (classify) {\n                brain.classify(inputs, gotResult)\n            }\n        }\n    }\n\n    // ==============================================================================================\n    // COLLECT\n    // ==============================================================================================\n\n    function collect() {\n        console.log(targetLabel);\n        collecting = true;\n        console.log(\"Collecting Data\");\n        setTimeout(() => {\n            collecting = false;\n            if(recordCount >= 1){\n                setLoadingStatus(\"Step 2: Click train and watch the Neural network learn!\")\n            }\n            setRecordStatus(\"\")\n        }, recordTime * 1000)\n    }\n\n    function handleRecord() {\n        setRecordCount(recordCount + 1)\n        targetLabel = inputEl.current.value\n        setRecordStatus(\"Recording\")\n        collect()\n    }\n\n\n    function handleTrain() {\n        brain.normalizeData();\n        brain.train({ epochs: 30 }, () => {\n            console.log(\"model trained\");\n            setLoadingStatus(\"Step 3: Click the classify button to try it out or click save to download your trained files!\")\n        })\n    }\n\n\n    // ==============================================================================================\n    // CLASSIFY\n    // ==============================================================================================\n\n    let inter;\n\n    function startClass() {\n        classify = true\n        displayClass()\n    }\n\n    function displayClass() {\n        setInterval(() => {\n            setRecordStatus(finalGesture);\n        }, 300)\n    }\n\n    function stopClass() {\n        classify = false;\n        finalGesture = \"\";\n    }\n\n    function gotResult(error, results) {\n        if (results[0].confidence > 0.87) {\n            console.log(results[0].label);\n            finalGesture = results[0].label;\n\n        }\n    }\n\n\n    async function handleSave() {\n        brain.save()\n    }\n\n    return (\n        <div>\n            <nav>\n                <h1>TRAIN-IT</h1>\n            </nav>\n            <div>\n                <h2>{loadingStatus}</h2>\n            </div>\n\n            <Webcam ref={webcamRef}\n                audio={false}\n                mirrored={true}\n                style={{\n                    width: 640,\n                    height: 480,\n                }} />\n            <div>\n                <div>\n                    <h2>{recordStatus}</h2>\n                </div>\n                <div>\n                    <input ref={inputEl} type=\"text\" />\n                    <button onClick={handleRecord}>Record</button>\n                </div>\n                <div>\n                    <div><h2>{recordCount + \" Hand Gestures Recorded!\"}</h2></div>\n                </div>\n                <button onClick={() => handleTrain()}>train</button>\n                <button onClick={() => startClass()}>Classify</button>\n                <button onClick={() => stopClass()}>Stop</button>\n                <button onClick={() => handleSave()}>save files to downloads</button>\n            </div>\n        </div>\n    )\n}\n\nexport default Collect\n","import React from 'react'\nimport './App.css';\nimport Collect from './pages/Collect';\n\n\nfunction App() {\n  return (\n    <div className=\"App\">\n      <Collect />\n    </div>\n  );\n}\n\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}